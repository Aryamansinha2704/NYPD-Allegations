{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Findings\n",
    "\n",
    "\n",
    "### Introduction\n",
    "Prediction Problem: Predicting the board_disposition of an allegation based on complainant Ethnicity, Gender, Age and Fado_type. \n",
    "\n",
    "These predicting variables have been choosen because they provide a good sense of the complainant and also the type of allegation. Also this gives both categorical and numerical variables. The choosen evaluation metric is accuracy because the output column has more than 2 possible outcomes(It will be engineered to have 3 outcomes) and this is a classification task.\n",
    "\n",
    "### Baseline Model\n",
    "The number of features are 4 of which 3 are nominal and 1 is quantitative. The model accuracy was roughly 48.69% which is not great but seeing as there are 3 possible outcomes, any accuracy of over 33% tells us something about the most likely outcome. The reason it is not great is because in a real life context being able to predict an outcome 48.69% is not of much use or value.\n",
    "\n",
    "### Final Model\n",
    "2 Features were engineered. Firstly, the complainant age feature was Standard Scaled and secondly, the complainant ethncity feature was Binarized to whether the ethnicity was Black or not. The standard scaling helped because each value now signified how extreme or close to the mean it was in terms of its distance from the mean in terms of Standard deviations. Binarizing the complainant ethncity should help if the theory of policing being harsher towards complainants of Black ethnicities is to be believed. Also seeing as some ethnicities have very little data, grouping them together might help the accuracy so they are treated similarly by the model.\n",
    "\n",
    "\n",
    "The choosen model was once again a Decision Tree Classifier. The parameters that performed best are as follows: max depth:4, min samples leaf: 2, min samples split: 2. The final accuracy was just over 50% which is an improvement but not as much as was hoped for.\n",
    "### Fairness Evaluation\n",
    "The interesting subset was choosen to be in the ethicity column - in particular, whether the model was more or less accurate for complainants of Black ethnicity compared to other ethnicities.\n",
    "\n",
    "Null Hypothesis: The model is fair, there is no significant difference in its accuracy between the two subsets.\n",
    "\n",
    "Alternative Hypothesis: The model is not fair, there is a significant difference in its accuracy between the two subsets.(two-sided)\n",
    "\n",
    "The permutation test failed to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Binarizer, QuantileTransformer, FunctionTransformer\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # Higher resolution figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Dataset and narrowing down on only the columns that will be used for prediction of board_disposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complainant_ethnicity</th>\n",
       "      <th>complainant_gender</th>\n",
       "      <th>complainant_age_incident</th>\n",
       "      <th>fado_type</th>\n",
       "      <th>board_disposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Substantiated (Command Lvl Instructions)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Offensive Language</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Substantiated (Charges)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Force</td>\n",
       "      <td>Substantiated (Command Discipline A)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33353</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Discourtesy</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33354</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Unsubstantiated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33355</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33356</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33357</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Abuse of Authority</td>\n",
       "      <td>Substantiated (Formalized Training)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33358 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      complainant_ethnicity complainant_gender  complainant_age_incident  \\\n",
       "0                     Black             Female                      38.0   \n",
       "1                     Black               Male                      26.0   \n",
       "2                     Black               Male                      26.0   \n",
       "3                     Black               Male                      45.0   \n",
       "4                       NaN                NaN                      16.0   \n",
       "...                     ...                ...                       ...   \n",
       "33353                 Asian               Male                      21.0   \n",
       "33354                 Asian               Male                      21.0   \n",
       "33355                 Asian               Male                      21.0   \n",
       "33356                 Asian               Male                      21.0   \n",
       "33357                 Asian               Male                      21.0   \n",
       "\n",
       "                fado_type                         board_disposition  \n",
       "0      Abuse of Authority  Substantiated (Command Lvl Instructions)  \n",
       "1             Discourtesy                   Substantiated (Charges)  \n",
       "2      Offensive Language                   Substantiated (Charges)  \n",
       "3      Abuse of Authority                   Substantiated (Charges)  \n",
       "4                   Force      Substantiated (Command Discipline A)  \n",
       "...                   ...                                       ...  \n",
       "33353         Discourtesy                           Unsubstantiated  \n",
       "33354  Abuse of Authority                           Unsubstantiated  \n",
       "33355  Abuse of Authority       Substantiated (Formalized Training)  \n",
       "33356  Abuse of Authority       Substantiated (Formalized Training)  \n",
       "33357  Abuse of Authority       Substantiated (Formalized Training)  \n",
       "\n",
       "[33358 rows x 5 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('allegations_202007271729-Copy1.csv')\n",
    "df = df[['complainant_ethnicity', 'complainant_gender', \n",
    "    'complainant_age_incident', 'fado_type', 'board_disposition']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to how it was done in Project 3, cleaning the board_disposition columnn to only include 3 possible outcomes - Substantiated, Unsubstantiated and Exonerated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_board_disposition(arg):\n",
    "    return arg.apply(lambda x: 'Subsantiated' if 'Substantiated' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = FunctionTransformer(clean_board_disposition)\n",
    "ft.fit(df['board_disposition'])\n",
    "df['board_disposition'] = ft.transform(df['board_disposition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into Training and Testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('board_disposition', axis = 1)\n",
    "y = df['board_disposition']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the baseline model with imputed NaN values, OneHotEncoding for categorical columns and using a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48691047162270185"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['complainant_ethnicity', 'complainant_gender', 'fado_type']\n",
    "cat_trans = Pipeline(steps = [('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('oh', OneHotEncoder())])\n",
    "preproc = ColumnTransformer([('cat', cat_trans, cat_cols),\n",
    "            ('num', SimpleImputer(strategy='constant', fill_value=0), ['complainant_age_incident'])])\n",
    "pl = Pipeline(steps = [('prep', preproc), ('class', DecisionTreeClassifier())])\n",
    "pl.fit(X_train, y_train)\n",
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the final model by onehotencoding fady_type and complainant_gender, Binarizing the ethnicity column through a functionTransformer and Standardizingly Scaling the age column while imputing missing values in all columns and using a Decision Tree Classifier. The complainant ethnicity column is being binarized in a manner wherein it would be True if its element is Black and False otherwise, this is due to the general debate around policing against this ethnicity in particular. Also certain ethnicities had very little data so that could have led to innacurate classifications in the Baseline model so treating all ethnicities other than Black the same in the model might improve its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4936051159072742"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['fado_type', 'complainant_gender']\n",
    "cat_trans = Pipeline(steps = [('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('oh', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "ethn_trans = Pipeline(steps = [('bin', FunctionTransformer(lambda x: x == \"Black\"))])\n",
    "age_trans = Pipeline(steps = [('num', SimpleImputer(strategy='constant', fill_value=0)), \n",
    "                        ('std', StandardScaler())])\n",
    "preproc = ColumnTransformer([('cat', cat_trans, cat_cols), \n",
    "                            ('fad', ethn_trans, ['complainant_ethnicity']), \n",
    "                            ('age', age_trans, ['complainant_age_incident'])])\n",
    "pl = Pipeline(steps = [('prep', preproc), ('class', DecisionTreeClassifier())])\n",
    "pl.fit(X_train, y_train)\n",
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is only slightly higher than the baseline score. Standardizing the age column was probably the biggest contributer to the increasing because binarizing the ethnicity column could have had the counter-effect of reducing the information given to make a classification as the number of categories of ethnicities was reduced to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now fine-tuning the model by finding the best parameters using GridSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'class__max_depth': [2,3,4,5,7,10,13,15,18,None], \n",
    "    'class__min_samples_split':[2,3,5,7,10,15,20],\n",
    "    'class__min_samples_leaf':[2,3,5,7,10,15,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = GridSearchCV(pl, param_grid = parameters, cv = 3, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class__max_depth': 4,\n",
       " 'class__min_samples_leaf': 2,\n",
       " 'class__min_samples_split': 2}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grids.fit(X_train, y_train)\n",
    "grids.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputting these parameters into the same model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5025979216626698"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = ['fado_type', 'complainant_gender']\n",
    "cat_trans = Pipeline(steps = [('imp', SimpleImputer(strategy='constant', fill_value='NULL')),\n",
    "    ('oh', OneHotEncoder(handle_unknown = 'ignore'))])\n",
    "ethn_trans = Pipeline(steps = [('bin', FunctionTransformer(lambda x: x == \"Asian\"))])\n",
    "age_trans = Pipeline(steps = [('num', SimpleImputer(strategy='constant', fill_value=0)), \n",
    "                        ('std', StandardScaler())])\n",
    "preproc = ColumnTransformer([('cat', cat_trans, cat_cols), \n",
    "                            ('fad', ethn_trans, ['complainant_ethnicity']), \n",
    "                            ('age', age_trans, ['complainant_age_incident'])])\n",
    "pl = Pipeline(steps = [('prep', preproc), ('class', DecisionTreeClassifier(max_depth = 4,\n",
    "                                                                min_samples_leaf = 2, \n",
    "                                                                min_samples_split = 2))])\n",
    "pl.fit(X_train, y_train)\n",
    "pl.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This accuracy of just over 50% is an improvement from the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fairness Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the model perform better when the complainant_ethnicity is Black vs not Black?\n",
    "\n",
    "The test-stat choosen is the absolute difference in accuracy between the two subsets because the outcome to be predicted is not Binary so getting a True Positive rate or something similar is up to interpretation of what is considered Positive so accuracy will provide a score of how often the model correctly predicts the board_disposition regardless of what the disposition actually is.\n",
    "\n",
    "Null Hypothesis: The model is fair, there is no significant difference in its accuracy between the two subsets.\n",
    "\n",
    "Alternative Hypothesis: The model is not fair, there is a significant difference in its accuracy between the two subsets.(two-sided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005597014925373123"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame({'complainant_ethnicity': X_test['complainant_ethnicity'], \n",
    "             'board_disposition': y_test, 'prediction': pl.predict(X_test)})\n",
    "black = test_df.loc[test_df['complainant_ethnicity'] == 'Black']\n",
    "black_acc = (black['prediction'] == black['board_disposition']).sum()/black.shape[0]\n",
    "other = test_df.loc[test_df['complainant_ethnicity'] != 'Black']\n",
    "other_acc = (other['prediction'] == other['board_disposition']).sum() / other.shape[0]\n",
    "test_stat = abs(other_acc - black_acc)\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test-stat obtained is 0.00559 approximately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the accuracy is only found for the test data set. The splitting is done in every simulation below to keep the size of the test set the same. The model is not re-fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = []\n",
    "for _ in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "    test_df = pd.DataFrame({'complainant_ethnicity': X_test['complainant_ethnicity'], \n",
    "             'board_disposition': y_test, 'prediction': pl.predict(X_test)})\n",
    "    black = test_df.loc[test_df['complainant_ethnicity'] == 'Black']\n",
    "    black_acc = (black['prediction'] == black['board_disposition']).sum()/black.shape[0]\n",
    "    other = test_df.loc[test_df['complainant_ethnicity'] != 'Black']\n",
    "    other_acc = (other['prediction'] == other['board_disposition']).sum() / other.shape[0]\n",
    "    obs.append(abs(other_acc - black_acc))\n",
    "np.count_nonzero(np.array(obs) >= test_stat) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value of 0.5 suggests that an outcome equally or more extreme than the test-stat is seen 50% of the time in the 100 simulations carried out which is far more than the default significance level of 5% so we fail to reject the null hypothesis and conclude the model can be called fair in regards to whether the complainaint has an ethnicity of Black or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
